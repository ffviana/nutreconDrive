{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_EU(X, p, alpha):\n",
    "    return p*(X**alpha)\n",
    "\n",
    "def get_pk(X_ref, p_ref, X_lot, p_lot, alpha, beta):\n",
    "    # get the probability of choosing lotery, from a set of X, p, and alpha and beta parameters\n",
    "    EUr = get_EU(X_ref, p_ref, alpha)\n",
    "    EUl = get_EU(X_lot, p_lot, alpha)\n",
    "    # changed the minus sign inside the exponent.\n",
    "    # standard logistic model, and simplify expressions (same result)\n",
    "    return 1/(1 + np.exp(-beta*(EUl - EUr))), EUr, EUl\n",
    "\n",
    "def get_choices(X_ref, p_ref, X_lot, p_lot, alpha, beta):\n",
    "    pk, EUr, EUl = get_pk(X_ref, p_ref, X_lot, p_lot, alpha, beta)\n",
    "    choices = np.random.uniform(size=EUl.shape)<pk\n",
    "    return choices, pk, EUr, EUl\n",
    "\n",
    "def get_nll_standard(X_ref, p_ref, X_lot, p_lot, choices, alpha, beta):\n",
    "    ''' compute neg-log-likelihood for a single experiment\n",
    "    inputs are:\n",
    "      - the parameters of the task (values and probabilities of lottery and reference)\n",
    "      - the subject's choices\n",
    "      - a guess on the subject parameteres (alpha and beta)\n",
    "    It uses the whole formula, which might be \"numerically unstable\" because of divisions by 0\n",
    "    '''\n",
    "    EUr = p_ref*X_ref**alpha\n",
    "    EUl = p_lot*X_lot**alpha\n",
    "    chose_ref = choices==False\n",
    "    ll_v = 1/(1 + np.exp(-beta*(EUl - EUr)))\n",
    "    ll_v[chose_ref] = 1 - ll_v[chose_ref]\n",
    "    return -np.sum(np.log(ll_v))\n",
    "\n",
    "def get_nll(X_ref, p_ref, X_lot, p_lot, choices, alpha, beta):\n",
    "    ''' compute neg-log-likelihood for a single experiment\n",
    "    inputs are:\n",
    "      - the parameters of the task (values and probabilities of lottery and reference)\n",
    "      - the subject's choices\n",
    "      - a guess on the subject parameteres (alpha and beta)\n",
    "    \n",
    "    Here we don't compute the likelihood with the whole logistic formula: pk = 1/(1+exp(-beta*(EUl-EUr))\n",
    "    We can use logarithmic properties to get rid of divisions (which I think is the point of using the -log-likelihood instead of the likelihood)\n",
    "    For the pos. choices, we use log(1/whatever) = log(1) - log(whatever) = -log(whatever)\n",
    "    For the neg. choices, we use log(1 - 1/(1+exp(y))) = log(exp(y)/(1+exp(y))) = y - log(1+exp(y))\n",
    "    Which is y + (thing_with_pos_choice)\n",
    "    As there are no divisions, no div/0 expected, but there still might be infinites (overflow) ¯\\_(ツ)_/¯\n",
    "    '''\n",
    "    # probably this is not complex enough to need its own function, save time in function calling\n",
    "    EUr = p_ref*X_ref**alpha \n",
    "    EUl = p_lot*X_lot**alpha\n",
    "\n",
    "    # Compute things once, sign flip to possibly save one operation\n",
    "    y = beta*(EUr - EUl)\n",
    "    chose_ref = choices==False\n",
    "\n",
    "    # values to be summed up, already negative:\n",
    "    nll_v = np.log(1 + np.exp(y))\n",
    "    nll_v[chose_ref] = nll_v[chose_ref] - y[chose_ref]\n",
    "    return np.sum(nll_v)\n",
    "\n",
    "\n",
    "def get_nll_clean(X_ref, p_ref, X_lot, p_lot, choices, alpha, beta):\n",
    "    ''' compute neg-log-likelihood for a single experiment\n",
    "    inputs are:\n",
    "      - the parameters of the task (values and probabilities of lottery and reference)\n",
    "      - the subject's choices\n",
    "      - a guess on the subject parameteres (alpha and beta)\n",
    "    \n",
    "    Here we don't compute the likelihood with the whole logistic formula: pk = 1/(1+exp(-beta*(EUl-EUr))\n",
    "    We can use logarithmic properties to get rid of divisions (which I think is the point of using the -log-likelihood instead of the likelihood)\n",
    "    For the pos. choices, we use log(1/whatever) = log(1) - log(whatever) = -log(whatever)\n",
    "    For the neg. choices, we use log(1 - 1/(1+exp(y))) = log(exp(y)/(1+exp(y))) = y - log(1+exp(y))\n",
    "    Which is y + (thing_with_pos_choice)\n",
    "    As there are no divisions, no div/0 expected, but there still might be infinites (overflow) ¯\\_(ツ)_/¯\n",
    "    '''\n",
    "    # probably this is not complex enough to need its own function, save time in function calling\n",
    "    EUr = p_ref*X_ref**alpha \n",
    "    EUl = p_lot*X_lot**alpha\n",
    "\n",
    "    # Compute things once, sign flip to possibly save one operation\n",
    "    y = beta*(EUr - EUl)\n",
    "    chose_ref = choices==False\n",
    "\n",
    "    # values to be summed up, already negative:\n",
    "    nll_v = np.log(1 + np.exp(y))\n",
    "    nll_v[chose_ref] = nll_v[chose_ref] - y[chose_ref]\n",
    "    return np.sum(nll_v[np.isfinite(nll_v)])\n",
    "\n",
    "def optimize_brute_force(X_ref, p_ref, X_lot, p_lot, choices, alpha_range, beta_range, steps, get_nll_fun=get_nll):\n",
    "    ''' compute -log-likelihood alpha/beta values within a range and with a resolution\n",
    "    return the alpha, beta and -log-likelihood grids\n",
    "    '''\n",
    "    alpha_vals = np.linspace(alpha_range[0], alpha_range[1], steps)\n",
    "    beta_vals = np.linspace(beta_range[0], beta_range[1], steps)\n",
    "\n",
    "    (alpha_grid, beta_grid) = np.meshgrid(alpha_vals, beta_vals)\n",
    "    alphabeta_shape = alpha_grid.shape\n",
    "    alpha_grid = alpha_grid.flatten()\n",
    "    beta_grid = beta_grid.flatten()\n",
    "\n",
    "    nll = [get_nll_fun(X_ref, p_ref, X_lot, p_lot, choices, alpha_grid[_], beta_grid[_]) \n",
    "           for _ in np.arange(len(alpha_grid))]\n",
    "    alpha_grid = alpha_grid.reshape(alphabeta_shape)    \n",
    "    beta_grid = beta_grid.reshape(alphabeta_shape)    \n",
    "    nll = np.asarray(nll).reshape(alphabeta_shape)\n",
    "    \n",
    "    return alpha_grid, beta_grid, nll\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on stability with a single \"subject\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject parameters\n",
    "alpha = 0.7\n",
    "beta = 0.8\n",
    "\n",
    "# task parameters\n",
    "X_ref = 20\n",
    "p_ref = 1\n",
    "X_vals = [20, 30, 40, 70, 100]\n",
    "p_vals = [.1, .25, .5, .75, .9]\n",
    "trialsPerComb = 6\n",
    "\n",
    "# get all combinations for trials\n",
    "(X_grid, p_grid) = np.meshgrid(X_vals, p_vals)\n",
    "X_cmb_unique = np.tile(X_grid.flatten(), trialsPerComb)\n",
    "p_cmb_unique = np.tile(p_grid.flatten(), trialsPerComb)\n",
    "X_lot_trials = np.tile(X_cmb_unique, trialsPerComb)\n",
    "p_lot_trials = np.tile(p_cmb_unique, trialsPerComb)\n",
    "\n",
    "\n",
    "choices, pk, EUr, EUl = get_choices(X_ref, p_ref, X_lot_trials, p_lot_trials, alpha, beta)\n",
    "\n",
    "\n",
    "# compare several nll functions:\n",
    "funs = (get_nll_standard, get_nll, get_nll_clean)\n",
    "fig = make_subplots(rows=1, cols=len(funs), subplot_titles=[_.__name__ for _ in funs])\n",
    "\n",
    "for k_fun in np.arange(len(funs)):\n",
    "    nll_fun = funs[k_fun]\n",
    "    print(f\"Using function {nll_fun.__name__}...\")\n",
    "    print('  computing...')\n",
    "    start_time = time.time()\n",
    "    nll = nll_fun(X_ref, p_ref, X_lot_trials, p_lot_trials, choices, alpha, beta)\n",
    "    end_time = time.time()\n",
    "    el_time = end_time-start_time\n",
    "    print(f'    {nll_fun.__name__} took {el_time} s')\n",
    "    print(f'    Result: {nll}')\n",
    "\n",
    "    # test numerical stability\n",
    "    print('testing stability...')\n",
    "    alpha_range = (0.1, 2)\n",
    "    beta_range = (-4, 4)\n",
    "    steps = 100\n",
    "    print('  computing brute force...')\n",
    "    alpha_grid, beta_grid, nll_map = optimize_brute_force(X_ref, p_ref, X_lot_trials, p_lot_trials, choices, alpha_range, beta_range, steps, get_nll_fun=nll_fun)\n",
    "\n",
    "    is_finite = np.sum(np.isfinite(nll_map.flatten()))\n",
    "    print(f'    {nll_fun.__name__}  got {is_finite} finite values ({100*is_finite/np.prod(nll_map.shape)} %)')\n",
    "\n",
    "    # plot the values for which it is numerically stable:\n",
    "    # set the color axis as logarithmic\n",
    "    print('    plotting the objective function in parameter space...')\n",
    "    z = nll_map\n",
    "    zlog = np.log(z)\n",
    "    (z_min, z_max) = (zlog[np.isfinite(zlog)].min(), zlog[np.isfinite(zlog)].max())\n",
    "    zax   = np.linspace(z_min, z_max, 5)\n",
    "    zax_t = np.exp(zax)\n",
    "\n",
    "    fig.add_trace(go.Contour(\n",
    "                    z=zlog,\n",
    "                    x=alpha_grid[1,:],\n",
    "                    y=beta_grid[:,1],\n",
    "                    colorbar={'title':\"-log-likelihood\"},\n",
    "                    hoverongaps = False,\n",
    "                    contours=dict(\n",
    "                        start=1,\n",
    "                        end=10,\n",
    "                        size=.5\n",
    "                    )),\n",
    "                    row=1, col=k_fun+1)\n",
    "\n",
    "    fig.add_scatter(x=[alpha], y = [beta], \n",
    "                    text = [\"true value\"], \n",
    "                    textposition=\"top center\", \n",
    "                    mode='markers+text', \n",
    "                    marker={\"color\":\"white\"}, \n",
    "                    textfont={'color':'white'}, \n",
    "                    hoverinfo=None,\n",
    "                    showlegend=False,\n",
    "                    row=1, col=k_fun+1)\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"alpha\",\n",
    "        row=1, col=k_fun+1)\n",
    "    fig.update_xaxes(\n",
    "        title_text=\"beta\",\n",
    "        row=1, col=k_fun+1)\n",
    "\n",
    "fig.update_layout(template='plotly_dark')\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the brute force optimization for several alpha/beta combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the brute force optimization for several alpha/beta combinations\n",
    "do_surf = False\n",
    "\n",
    "# repeat everything for several true values\n",
    "X_ref = 20\n",
    "p_ref = 1\n",
    "X_lot = 30\n",
    "p_lot = .75\n",
    "\n",
    "# get all possible combinations\n",
    "X_vals = [20, 30, 40, 70, 100]\n",
    "p_vals = [.1, .25, .5, .75, .9]\n",
    "trialsPerComb = 6\n",
    "\n",
    "# combinations\n",
    "(X_grid, p_grid) = np.meshgrid(X_vals, p_vals)\n",
    "X_cmb_unique = np.tile(X_grid.flatten(), trialsPerComb)\n",
    "p_cmb_unique = np.tile(p_grid.flatten(), trialsPerComb)\n",
    "X_lot_trials = np.tile(X_cmb_unique, trialsPerComb)\n",
    "p_lot_trials = np.tile(p_cmb_unique, trialsPerComb)\n",
    "\n",
    "\n",
    "alpha_true_vals = np.linspace(0.1, 1.5, 8)\n",
    "beta_true_vals = np.linspace(-2, .5, 2)\n",
    "\n",
    "(alpha_true_grid, beta_true_grid) = np.meshgrid(alpha_true_vals, beta_true_vals)\n",
    "alphabeta_shape = alpha_true_grid.shape\n",
    "alpha_true_grid = alpha_true_grid.flatten()\n",
    "beta_true_grid = beta_true_grid.flatten()\n",
    "\n",
    "# plot the results\n",
    "for k1 in np.arange(len(alpha_true_grid)):\n",
    "    print(f'{(k1+1)}/{len(alpha_true_grid)}')\n",
    "\n",
    "    print('generating choices...')\n",
    "    choices, pk, EUr, EUl = get_choices(X_ref, p_ref, X_lot_trials, p_lot_trials, alpha_true_grid[k1], beta_true_grid[k1])\n",
    "    \n",
    "    # Optimize (brute force)\n",
    "    alpha_range = (-2, 2)\n",
    "    beta_range = (-4, 4)\n",
    "    steps = 100\n",
    "\n",
    "    print('running brute force...')\n",
    "    funs = (get_nll, get_nll_clean)\n",
    "    fig = make_subplots(rows=1, cols=len(funs), subplot_titles=[_.__name__ for _ in funs])\n",
    "    for k_fun in np.arange(len(funs)):\n",
    "        nll_fun = funs[k_fun]\n",
    "        alpha_grid, beta_grid, nll = optimize_brute_force(X_ref, p_ref, X_lot_trials, p_lot_trials, choices, alpha_range, beta_range, steps, get_nll_fun=nll_fun)\n",
    "\n",
    "\n",
    "        (z_min, z_max) = (nll[np.isfinite(nll)].min(), nll[np.isfinite(nll)].max())\n",
    "\n",
    "        print('plotting...')\n",
    "        '''\n",
    "        fig = go.Figure(layout={\n",
    "            \"template\":\"plotly_dark\",\n",
    "            \"scene\":{\n",
    "            \"camera\":{\n",
    "                \"projection\":{\"type\":\"orthographic\"}\n",
    "                }\n",
    "            }\n",
    "            })\n",
    "        '''\n",
    "        # log axis\n",
    "        z = nll\n",
    "        zlog = np.log(z)\n",
    "        (z_min, z_max) = (zlog[np.isfinite(zlog)].min(), zlog[np.isfinite(zlog)].max())\n",
    "        zax   = np.linspace(1, 10, 40)\n",
    "        zax_t = np.exp(zax)\n",
    "\n",
    "        fig.add_trace(go.Contour(z=zlog, \n",
    "                                    x=alpha_grid[1,:], \n",
    "                                    y=beta_grid[:,1],\n",
    "                                    colorbar={'title':'-log-likelihood', \n",
    "                                            \"tickvals\":zax, \n",
    "                                            \"ticktext\":zax_t},\n",
    "                                    hoverongaps = False,contours=dict(start=1,end=10,size=.25)),row=1,col=k_fun+1)\n",
    "        fig.add_trace(go.Scatter(x=[alpha_true_grid[k1]], y = [beta_true_grid[k1]], \n",
    "                                    text = [\"true value\"], \n",
    "                                    textposition=\"top center\", \n",
    "                                    mode='markers+text',\n",
    "                                    marker={\"color\":\"white\"},\n",
    "                                    textfont={'color':'white'}, \n",
    "                                    hoverinfo=None, \n",
    "                                    showlegend=False),\n",
    "                                    row=1,col=k_fun+1)\n",
    "        fig.update_layout(xaxis_title_text='alpha',  \n",
    "                    yaxis_title_text='beta')\n",
    "\n",
    "\n",
    "\n",
    "    fig.update_layout(template=\"plotly_dark\",\n",
    "                          scene={\"camera\":{\"projection\":{\"type\":\"orthographic\"}}})\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the brute force optimization for several alpha/beta combinations (one X-p combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the brute force optimization for several alpha/beta combinations (only one lottery combination, should be ill-posed)\n",
    "\n",
    "# repeat everything for several true values\n",
    "X_ref = 20\n",
    "p_ref = 1\n",
    "X_lot = 30\n",
    "p_lot = .75\n",
    "\n",
    "# get all possible combinations\n",
    "X_vals = [40]\n",
    "p_vals = [.5]\n",
    "trialsPerComb = 100 # more trials, since we have less data\n",
    "\n",
    "# combinations\n",
    "(X_grid, p_grid) = np.meshgrid(X_vals, p_vals)\n",
    "X_cmb_unique = np.tile(X_grid.flatten(), trialsPerComb)\n",
    "p_cmb_unique = np.tile(p_grid.flatten(), trialsPerComb)\n",
    "X_lot_trials = np.tile(X_cmb_unique, trialsPerComb)\n",
    "p_lot_trials = np.tile(p_cmb_unique, trialsPerComb)\n",
    "\n",
    "\n",
    "alpha_true_vals = np.linspace(0.1, 1.5, 8)\n",
    "beta_true_vals = np.linspace(-2, .5, 2)\n",
    "\n",
    "(alpha_true_grid, beta_true_grid) = np.meshgrid(alpha_true_vals, beta_true_vals)\n",
    "alphabeta_shape = alpha_true_grid.shape\n",
    "alpha_true_grid = alpha_true_grid.flatten()\n",
    "beta_true_grid = beta_true_grid.flatten()\n",
    "\n",
    "# plot the results\n",
    "for k1 in np.arange(len(alpha_true_grid)):\n",
    "    print(f'{(k1+1)}/{len(alpha_true_grid)}')\n",
    "\n",
    "    print('generating choices...')\n",
    "    choices, pk, EUr, EUl = get_choices(X_ref, p_ref, X_lot_trials, p_lot_trials, alpha_true_grid[k1], beta_true_grid[k1])\n",
    "    \n",
    "    # Optimize (brute force)\n",
    "    alpha_range = (-2, 2)\n",
    "    beta_range = (-4, 4)\n",
    "    steps = 100\n",
    "\n",
    "    print('running brute force...')\n",
    "    funs = (get_nll, get_nll_clean)\n",
    "    fig = make_subplots(rows=1, cols=len(funs), subplot_titles=[_.__name__ for _ in funs])\n",
    "    for k_fun in np.arange(len(funs)):\n",
    "        nll_fun = funs[k_fun]\n",
    "        alpha_grid, beta_grid, nll = optimize_brute_force(X_ref, p_ref, X_lot_trials, p_lot_trials, choices, alpha_range, beta_range, steps, get_nll_fun=nll_fun)\n",
    "\n",
    "\n",
    "        (z_min, z_max) = (nll[np.isfinite(nll)].min(), nll[np.isfinite(nll)].max())\n",
    "\n",
    "        print('plotting...')\n",
    "        '''\n",
    "        fig = go.Figure(layout={\n",
    "            \"template\":\"plotly_dark\",\n",
    "            \"scene\":{\n",
    "            \"camera\":{\n",
    "                \"projection\":{\"type\":\"orthographic\"}\n",
    "                }\n",
    "            }\n",
    "            })\n",
    "        '''\n",
    "        # log axis\n",
    "        z = nll\n",
    "        zlog = np.log(z)\n",
    "        (z_min, z_max) = (zlog[np.isfinite(zlog)].min(), zlog[np.isfinite(zlog)].max())\n",
    "        zax   = np.linspace(1, 10, 40)\n",
    "        zax_t = np.exp(zax)\n",
    "\n",
    "        fig.add_trace(go.Contour(z=zlog, \n",
    "                                    x=alpha_grid[1,:], \n",
    "                                    y=beta_grid[:,1],\n",
    "                                    colorbar={'title':'-log-likelihood', \n",
    "                                            \"tickvals\":zax, \n",
    "                                            \"ticktext\":zax_t},\n",
    "                                    hoverongaps = False,contours=dict(start=1,end=10,size=.25)),row=1,col=k_fun+1)\n",
    "        fig.add_trace(go.Scatter(x=[alpha_true_grid[k1]], y = [beta_true_grid[k1]], \n",
    "                                    text = [\"true value\"], \n",
    "                                    textposition=\"top center\", \n",
    "                                    mode='markers+text',\n",
    "                                    marker={\"color\":\"white\"},\n",
    "                                    textfont={'color':'white'}, \n",
    "                                    hoverinfo=None, \n",
    "                                    showlegend=False),\n",
    "                                    row=1,col=k_fun+1)\n",
    "        fig.update_layout(xaxis_title_text='alpha',  \n",
    "                    yaxis_title_text='beta')\n",
    "\n",
    "\n",
    "\n",
    "    fig.update_layout(template=\"plotly_dark\",\n",
    "                          scene={\"camera\":{\"projection\":{\"type\":\"orthographic\"}}})\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
